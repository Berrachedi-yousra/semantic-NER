{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import os\n",
    "#os.chdir(r'C:\\Users\\ASUS\\Desktop\\PFE\\dataset')\n",
    "\n",
    "with open('semantic_final_train.json', 'r', encoding='utf-8') as f:\n",
    "    data = json.load(f)\n",
    "    \n",
    "#os.chdir(r'C:\\Users\\ASUS\\Desktop\\PFE\\dataset')\n",
    "\n",
    "with open('semantic_final_test.json', 'r', encoding='utf-8') as f:\n",
    "    data2 = json.load(f)\n",
    "\n",
    "entity_name = \"NUMBERS/METRICS\"\n",
    "\n",
    "train_data = data['annotations']\n",
    "test_data = data2['annotations']\n",
    "train_data = [tuple(i) for i in train_data]\n",
    "test_data = [tuple(i) for i in test_data]\n",
    "for i in train_data:\n",
    "    if i[1]['entities'] == []:\n",
    "        i[1]['entities'] = (0, 0, entity_name)\n",
    "    else:\n",
    "        i[1]['entities'][0] = tuple(i[1]['entities'][0])\n",
    "\n",
    "        \n",
    "for i in test_data:\n",
    "    if i[1]['entities'] == []:\n",
    "        i[1]['entities'] = (0, 0, entity_name)\n",
    "    else:\n",
    "        i[1]['entities'][0] = tuple(i[1]['entities'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 37%|███▋      | 164/446 [00:00<00:00, 854.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping entity\n",
      "Skipping entity\n",
      "Skipping entity\n",
      "Skipping entity\n",
      "Skipping entity\n",
      "Skipping entity\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 446/446 [00:00<00:00, 851.23it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping entity\n",
      "Skipping entity\n",
      "Skipping entity\n",
      "Skipping entity\n",
      "Skipping entity\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import spacy\n",
    "from spacy.tokens import DocBin\n",
    "\n",
    "nlp = spacy.blank(\"fr-CA\") # load a new spacy model\n",
    "#nlp = spacy.load(\"en_core_web_sm\") # load other spacy model\n",
    "\n",
    "db = DocBin() # create a DocBin object\n",
    "for text, annot in tqdm(train_data): # data in previous format\n",
    "    doc = nlp.make_doc(text) # create doc object from text\n",
    "    ents = []\n",
    "    for start, end, label in annot[\"entities\"]: # add character indexes\n",
    "        span = doc.char_span(start, end, label=label, alignment_mode=\"contract\")\n",
    "        if span is None:\n",
    "            print(\"Skipping entity\")\n",
    "        else:\n",
    "            ents.append(span)\n",
    "    doc.ents = ents # label the text with the ents\n",
    "    db.add(doc)\n",
    "\n",
    "os.chdir(r'C:/Users/ASUS/Desktop/PFE_models/semantic_model')\n",
    "db.to_disk(\"./train.spacy\") # save the docbin object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 106/106 [00:00<00:00, 1517.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping entity\n",
      "Skipping entity\n",
      "Skipping entity\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import spacy\n",
    "from spacy.tokens import DocBin\n",
    "\n",
    "nlp2 = spacy.blank(\"fr-CA\") # load a new spacy model\n",
    "#nlp = spacy.load(\"en_core_web_sm\") # load other spacy model\n",
    "\n",
    "db2 = DocBin() # create a DocBin object\n",
    "\n",
    "for text, annot in tqdm(test_data): # data in previous format\n",
    "    doc2 = nlp2.make_doc(text) # create doc object from text\n",
    "    ents2 = []\n",
    "    for start, end, label in annot[\"entities\"]: # add character indexes\n",
    "        span2 = doc2.char_span(start, end, label=label, alignment_mode=\"contract\")\n",
    "        if span2 is None:\n",
    "            print(\"Skipping entity\")\n",
    "        else:\n",
    "            ents2.append(span2)\n",
    "    doc2.ents = ents2 # label the text with the ents\n",
    "    db2.add(doc2)\n",
    "\n",
    "os.chdir(r'C:\\Users\\ASUS\\Desktop\\PFE_models\\semantic_model')\n",
    "db2.to_disk(\"./test.spacy\") # save the docbin object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✔ Auto-filled config with all values\n",
      "✔ Saved config\n",
      "config.cfg\n",
      "You can now add your data and train your pipeline:\n",
      "python -m spacy train config.cfg --paths.train ./train.spacy --paths.dev ./dev.spacy\n"
     ]
    }
   ],
   "source": [
    "!python -m spacy init fill-config base_config.cfg config.cfg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ℹ Saving to output directory: output\n",
      "ℹ Using CPU\n",
      "\u001b[1m\n",
      "=========================== Initializing pipeline ===========================\u001b[0m\n",
      "✔ Initialized pipeline\n",
      "\u001b[1m\n",
      "============================= Training pipeline =============================\u001b[0m\n",
      "ℹ Pipeline: ['tok2vec', 'ner']\n",
      "ℹ Initial learn rate: 0.001\n",
      "E    #       LOSS TOK2VEC  LOSS NER  ENTS_F  ENTS_P  ENTS_R  SCORE \n",
      "---  ------  ------------  --------  ------  ------  ------  ------\n",
      "  0       0          0.00     54.59    0.00    0.00    0.00    0.00\n",
      "  1     200       1316.40   3093.94   69.93   81.71   61.11    0.70\n",
      "  3     400        625.14   1311.32   75.69   81.68   70.51    0.76\n",
      "  6     600        300.37    709.77   74.55   79.61   70.09    0.75\n",
      " 10     800        267.49    396.34   77.40   81.22   73.93    0.77\n",
      " 14    1000        250.55    254.66   75.11   76.79   73.50    0.75\n",
      " 19    1200        270.71    140.27   74.61   78.67   70.94    0.75\n",
      " 25    1400         97.44     43.49   77.97   80.45   75.64    0.78\n",
      " 33    1600        159.54     54.11   77.75   81.99   73.93    0.78\n",
      " 43    1800        468.22     99.79   77.88   80.73   75.21    0.78\n",
      " 54    2000        288.20     66.44   77.06   80.47   73.93    0.77\n",
      " 69    2200        461.41     92.05   76.13   80.48   72.22    0.76\n",
      " 86    2400        452.54     67.36   75.63   80.98   70.94    0.76\n",
      "104    2600        331.93     51.01   74.67   76.34   73.08    0.75\n",
      "122    2800        671.09     93.38   76.38   79.00   73.93    0.76\n",
      "140    3000        158.26     23.56   75.89   79.44   72.65    0.76\n",
      "✔ Saved pipeline to output directory\n",
      "output\\model-last\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2023-05-18 09:30:05,789] [INFO] Set up nlp object from config\n",
      "[2023-05-18 09:30:05,803] [INFO] Pipeline: ['tok2vec', 'ner']\n",
      "[2023-05-18 09:30:05,806] [INFO] Created vocabulary\n",
      "[2023-05-18 09:30:05,823] [INFO] Finished initializing nlp object\n",
      "[2023-05-18 09:30:06,559] [INFO] Initialized pipeline components: ['tok2vec', 'ner']\n"
     ]
    }
   ],
   "source": [
    "!python -m spacy train config.cfg --output ./output --paths.train ./train.spacy --paths.dev ./test.spacy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">Je dois avouer que \n",
       "<mark class=\"entity\" style=\"background: #33E7FF; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    @mic\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">TAG</span>\n",
       "</mark>\n",
       " est le meilleur, il a \n",
       "<mark class=\"entity\" style=\"background: #EF0000; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    25 ans\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">NUMBERS/METRICS</span>\n",
       "</mark>\n",
       " d'expérience dans l'industrie. C'est génial! Voici son compte si vous voulez le suivre: \n",
       "<mark class=\"entity\" style=\"background: #FF33A2; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    https:/champ.indus.com\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">LINK</span>\n",
       "</mark>\n",
       "</div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "semantic = spacy.load(r\".\\output\\model-best\") #load the best model\n",
    "doc = semantic(\"Je dois avouer que @mic est le meilleur, il a 25 ans d'expérience dans l'industrie. C'est génial! Voici son compte si vous voulez le suivre: https:/champ.indus.com\") # input sample text\n",
    "colors = {\"TAG\": \"#33E7FF\", \"NUMBERS/METRICS\": \"#EF0000\", \"QUESTION\": \"#FF9533\", \"GOVERNING ENTITY\": \"#3C33FF\", \"REFERENCE\": \"#49FF33\", \"HASHTAG\": \"#EEFF33\", \"LINK\": \"#FF33A2\", \"EMOTICON\": \"#95A1A3\"}\n",
    "options = {\"colors\": colors} \n",
    "spacy.displacy.render(doc, style=\"ent\", options= options, jupyter=True) # display in Jupyter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">La vitesse maximum était à \n",
       "<mark class=\"entity\" style=\"background: #EF0000; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    120 km/h\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">NUMBERS/METRICS</span>\n",
       "</mark>\n",
       " mais les conducteurs ne la respectent pas. La police doit faire quelque chose! \n",
       "<mark class=\"entity\" style=\"background: #EEFF33; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    #vitesse\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">HASHTAG</span>\n",
       "</mark>\n",
       "</div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "doc1 = semantic(\"La vitesse maximum était à 120 km/h mais les conducteurs ne la respectent pas. La police doit faire quelque chose! #vitesse\")\n",
    "\n",
    "spacy.displacy.render(doc1, style=\"ent\", options= options, jupyter=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">C'était magnifique la dernière fois à l'Opéra \n",
       "<mark class=\"entity\" style=\"background: #95A1A3; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    :)\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">EMOTICON</span>\n",
       "</mark>\n",
       " \n",
       "<mark class=\"entity\" style=\"background: #FF9533; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Pourquoi pas venir avec nous la prochaine fois?\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">QUESTION</span>\n",
       "</mark>\n",
       "</div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "doc2 = semantic(\"C'était magnifique la dernière fois à l'Opéra :) Pourquoi pas venir avec nous la prochaine fois?\")\n",
    "\n",
    "spacy.displacy.render(doc2, style=\"ent\", options= options, jupyter=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text: {':)'}\n",
      "Type: {'EMOTICON'}\n",
      "Text: {'Pourquoi pas venir avec nous la prochaine fois?'}\n",
      "Type: {'QUESTION'}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cmt_ID</th>\n",
       "      <th>comment</th>\n",
       "      <th>question</th>\n",
       "      <th>gov_ent</th>\n",
       "      <th>reference</th>\n",
       "      <th>num_met</th>\n",
       "      <th>sem_hashtag</th>\n",
       "      <th>tag</th>\n",
       "      <th>link</th>\n",
       "      <th>emoticon</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12575</td>\n",
       "      <td>C'ï¿½tait magnifique la derniï¿½re fois ï¿½ l'...</td>\n",
       "      <td>Pourquoi pas venir avec nous la prochaine fois?,</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>:),</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>12577</td>\n",
       "      <td>La vitesse maximal ï¿½tait ï¿½ 120 km/h mais l...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>police ne,</td>\n",
       "      <td>NaN</td>\n",
       "      <td>120 km/h,</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12575</td>\n",
       "      <td>C'était magnifique la dernière fois à l'Opéra ...</td>\n",
       "      <td>Pourquoi pas venir avec nous la prochaine fois?,</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>:),</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   cmt_ID                                            comment  \\\n",
       "0   12575  C'ï¿½tait magnifique la derniï¿½re fois ï¿½ l'...   \n",
       "1   12577  La vitesse maximal ï¿½tait ï¿½ 120 km/h mais l...   \n",
       "2   12575  C'était magnifique la dernière fois à l'Opéra ...   \n",
       "\n",
       "                                           question     gov_ent  reference  \\\n",
       "0  Pourquoi pas venir avec nous la prochaine fois?,         NaN        NaN   \n",
       "1                                               NaN  police ne,        NaN   \n",
       "2  Pourquoi pas venir avec nous la prochaine fois?,         NaN        NaN   \n",
       "\n",
       "     num_met  sem_hashtag  tag  link emoticon  \n",
       "0        NaN          NaN  NaN   NaN      :),  \n",
       "1  120 km/h,          NaN  NaN   NaN      NaN  \n",
       "2        NaN          NaN  NaN   NaN      :),  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question_string = ''\n",
    "gov_ent_string = ''\n",
    "reference_string = ''\n",
    "num_met_string = ''\n",
    "hashtag_string = ''\n",
    "tag_string = ''\n",
    "link_string = ''\n",
    "emoticon_string = ''\n",
    "\n",
    "for ent in doc.ents:    \n",
    "        # check if entity is equal 'QUESTION'\n",
    "        if ent.label_ in ['QUESTION']:\n",
    "            print('Text:', {ent.text})\n",
    "            print('Type:', {ent.label_})\n",
    "            x = ent.text \n",
    "            question_string = question_string + x + ','\n",
    "\n",
    "        if ent.label_ in ['GOVERNING ENTITY']:\n",
    "            print('Text:', {ent.text})\n",
    "            print('Type:', {ent.label_})\n",
    "            x = ent.text \n",
    "            gov_ent_string = gov_ent_string + x + ','\n",
    "\n",
    "        if ent.label_ in ['REFERENCE']:\n",
    "            print('Text:', {ent.text})\n",
    "            print('Type:', {ent.label_})\n",
    "            x = ent.text \n",
    "            reference_string = reference_string + x + ','\n",
    "\n",
    "        if ent.label_ in ['NUMBERS/METRICS']:\n",
    "            print('Text:', {ent.text})\n",
    "            print('Type:', {ent.label_})\n",
    "            x = ent.text \n",
    "            num_met_string = num_met_string + x + ','\n",
    "\n",
    "        if ent.label_ in ['HASHTAG']:\n",
    "            print('Text:', {ent.text})\n",
    "            print('Type:', {ent.label_})\n",
    "            x = ent.text \n",
    "            hashtag_string = hashtag_string + x + ','\n",
    "\n",
    "        if ent.label_ in ['TAG']:\n",
    "            print('Text:', {ent.text})\n",
    "            print('Type:', {ent.label_})\n",
    "            x = ent.text \n",
    "            tag_string = tag_string + x + ','\n",
    "\n",
    "        if ent.label_ in ['LINK']:\n",
    "            print('Text:', {ent.text})\n",
    "            print('Type:', {ent.label_})\n",
    "            x = ent.text \n",
    "            link_string = link_string + x + ','\n",
    "\n",
    "        if ent.label_ in ['EMOTICON']:\n",
    "            print('Text:', {ent.text})\n",
    "            print('Type:', {ent.label_})\n",
    "            x = ent.text \n",
    "            emoticon_string = emoticon_string + x + ','\n",
    "\n",
    "import csv\n",
    "import pandas as pd\n",
    "from csv import writer\n",
    "\n",
    "input_variable = ['12575', doc, question_string, gov_ent_string, reference_string, num_met_string, hashtag_string, tag_string, link_string, emoticon_string]\n",
    "\n",
    "with open('output_semantic.csv', 'a') as f1_object:\n",
    " \n",
    "    # Pass this file object to csv.writer()\n",
    "    # and get a writer object\n",
    "    writer_object = writer(f1_object)\n",
    " \n",
    "    #create a new row for the comment   \n",
    "    writer_object.writerow(input_variable)\n",
    "\n",
    "    # Close the file object\n",
    "    f1_object.close()\n",
    "\n",
    "fileContent = pd.read_csv(\"output_semantic.csv\", encoding='latin-1')\n",
    "fileContent\n",
    "\n",
    "            "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "vscode": {
   "interpreter": {
    "hash": "369f2c481f4da34e4445cda3fffd2e751bd1c4d706f27375911949ba6bb62e1c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
